# -*- coding: utf-8 -*-
"""Sistem_Rekomendasi_Anime_Content_Based_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/NaufalNurFahriza/Machine-Learning-Terapan-Sistem-Rekomendasi-dicoding/blob/main/Sistem_Rekomendasi_Anime_Content_Based_v2.ipynb

# Sistem Rekomendasi Anime dengan Content-Based Filtering

## 1. Business Understanding
Sistem rekomendasi anime ini dirancang untuk membantu pengguna menemukan anime baru berdasarkan preferensi konten dari anime yang mereka sukai sebelumnya. Pendekatan yang digunakan adalah **Content-Based Filtering**.

**Manfaat bisnis:**
- Meningkatkan engagement pengguna di platform anime
- Memperkenalkan anime baru yang sesuai minat
- Meningkatkan retensi pengguna

## 2. Import Libraries
Library berikut digunakan untuk pemrosesan data, visualisasi, dan pembuatan sistem rekomendasi.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import save_npz
import joblib
import warnings
import re
import string
warnings.filterwarnings('ignore')

"""## 3. Data Loading
Memuat dataset `Top_Anime_data.csv` yang berisi informasi tentang anime populer tahun 2024.
"""

# Install & setup Kaggle
!pip install -q kaggle
from google.colab import files
files.upload()  # Upload kaggle.json
!mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

# Download & extract dataset
!kaggle datasets download -d bhavyadhingra00020/top-anime-dataset-2024
import zipfile
with zipfile.ZipFile('top-anime-dataset-2024.zip', 'r') as z:
    z.extractall('.')

# Load data dengan fallback encoding
for enc in ['utf-8', 'ISO-8859-1', 'latin1']:
    try:
        anime_df = pd.read_csv('Top_Anime_data.csv', encoding=enc)
        print(f"Data berhasil dimuat dengan encoding: {enc}")
        break
    except:
        continue

# Tampilkan info dasar
print(f"\nShape: {anime_df.shape}")
print("\n5 data pertama:")
display(anime_df.head())

"""## 4. Data Understanding
Menampilkan informasi umum dan distribusi nilai pada dataset.
"""

# Info dataset
anime_df.info()

# analisis missing values dari data awal
missing_data = anime_df.isnull().sum()
missing_percentage = (missing_data / len(anime_df)) * 100

missing_df = pd.DataFrame({
    'Missing Count': missing_data,
    'Missing Percentage': missing_percentage
})
missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)
print(missing_df)

print(f"\nKolom dengan missing values terbanyak:")
print(f"- Synonyms: {missing_data['Synonyms']} missing values ({missing_percentage['Synonyms']:.1f}%)")
print(f"- Premiered: {missing_data['Premiered']} missing values ({missing_percentage['Premiered']:.1f}%)")
print(f"- Broadcast: {missing_data['Broadcast']} missing values ({missing_percentage['Broadcast']:.1f}%)")
print(f"- Demographic: {missing_data['Demographic']} missing values ({missing_percentage['Demographic']:.1f}%)")
print(f"- Genres: {missing_data['Genres']} missing values ({missing_percentage['Genres']:.1f}%)")

# Statistik deskriptif
anime_df.describe()

"""### Distribusi Skor Rating"""

plt.figure(figsize=(10,6))
sns.histplot(anime_df['Score'], bins=20, kde=True)
plt.title('Distribusi Rating Anime')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()

"""### Top 10 Anime Berdasarkan Rating"""

top_anime = anime_df.sort_values('Score', ascending=False).head(10)
plt.figure(figsize=(12,8))
sns.barplot(x='Score', y='English', data=top_anime, palette='viridis')
plt.title('Top 10 Anime Berdasarkan Rating')
plt.xlabel('Rating')
plt.ylabel('Judul Anime')
plt.tight_layout()
plt.show()

"""###Analisis genre"""

# Hitung genre yang tidak null
genres_valid = anime_df['Genres'].dropna()
all_genres = []
for genres in genres_valid:
    if isinstance(genres, str):
        genre_list = [g.strip() for g in genres.split(',')]
        all_genres.extend(genre_list)

genre_counts = pd.Series(all_genres).value_counts().head(15)
plt.figure(figsize=(12,8))
sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='Set2')
plt.title('Top 15 Genre Anime Paling Populer')
plt.xlabel('Jumlah Anime')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""## 5. Data Preparation

"""

# Pengecekan Data Duplikat
print("=== PENGECEKAN DATA DUPLIKAT ===")
duplicates = anime_df.duplicated().sum()
print(f"Jumlah data duplikat: {duplicates}")

if duplicates > 0:
    print("Menghapus data duplikat...")
    anime_df = anime_df.drop_duplicates()
    print(f"Shape setelah menghapus duplikat: {anime_df.shape}")
else:
    print("Tidak ada data duplikat ditemukan.")

"""### Handling Missing Values"""

# Isi missing values
anime_df['Description'] = anime_df['Description'].fillna('No description available')
anime_df['Genres'] = anime_df['Genres'].fillna('Unknown')
anime_df['Type'] = anime_df['Type'].fillna('Unknown')
anime_df['Demographic'] = anime_df['Demographic'].fillna('Unknown')
anime_df['Source'] = anime_df['Source'].fillna('Unknown')

"""### Feature Engineering
Menggabungkan fitur konten menjadi satu kolom.
"""

anime_df['content_features'] = anime_df['Genres'] + ' ' + anime_df['Type'] + ' ' + anime_df['Description']
anime_df['content_features'] = anime_df['content_features'].str.lower()

"""## 6. Modeling dengan TF-IDF dan Cosine Similarity"""

# TF-IDF Vectorization
tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=5000)
tfidf_matrix = tfidf.fit_transform(anime_df['content_features'])

print("Shape TF-IDF Matrix:", tfidf_matrix.shape)

# Cosine Similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix, dense_output=False)
save_npz('cosine_sim_matrix.npz', cosine_sim)
print("Shape Similarity Matrix:", cosine_sim.shape)

"""## 7. Fungsi Rekomendasi Anime

Memberikan rekomendasi anime berdasarkan kesamaan konten
    
    Parameters:
    title (str): Judul anime dalam bahasa Inggris
    cosine_sim: Matrix similarity
    df: DataFrame anime
    top_n (int): Jumlah rekomendasi yang diinginkan
    
    Returns:
    DataFrame: Rekomendasi anime dengan similarity score
"""

def get_enhanced_recommendations(title, cosine_sim=cosine_sim, df=anime_df, top_n=10):
    try:
        # Cari index anime berdasarkan judul
        idx = df[df['English'] == title].index
        if len(idx) == 0:
            print(f"Anime dengan judul '{title}' tidak ditemukan.")
            print("Judul yang tersedia (contoh 10 pertama):")
            print(df['English'].head(10).tolist())
            return None

        idx = idx[0]

        # Hitung similarity scores
        sim_scores = list(enumerate(cosine_sim[idx].toarray().flatten()))

        # Sort berdasarkan similarity score (descending)
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]

        # Ambil indices dan similarity values
        anime_indices = [i[0] for i in sim_scores]
        similarity_values = [i[1] for i in sim_scores]

        # Buat DataFrame rekomendasi
        recommendations = df[['English', 'Genres', 'Score', 'Type', 'Episodes', 'Studios', 'Demographic']].iloc[anime_indices].copy()
        recommendations['Similarity'] = similarity_values

        # Reorder kolom
        recommendations = recommendations[['English', 'Similarity', 'Score', 'Genres', 'Type', 'Episodes', 'Demographic', 'Studios']]

        return recommendations

    except Exception as e:
        print(f"Error: {e}")
        return None

"""## 8. Contoh Penggunaan Rekomendasi"""

print("=== CONTOH PENGGUNAAN SISTEM REKOMENDASI ===")

# Test dengan beberapa anime populer
test_animes = [
    "Attack on Titan Season 3 Part 2",
    "Fullmetal Alchemist: Brotherhood",
    "Steins;Gate",
    "Death Note",
    "Your Name"
]

recommendation_results = {}

for anime_title in test_animes:
    print(f"\n=== Rekomendasi untuk '{anime_title}' ===")
    recommendations = get_enhanced_recommendations(anime_title, top_n=10)

    if recommendations is not None:
        recommendation_results[anime_title] = recommendations
        display(recommendations)

        # Tampilkan insight
        avg_similarity = recommendations['Similarity'].mean()
        max_similarity = recommendations['Similarity'].max()
        print(f"Rata-rata similarity: {avg_similarity:.4f}")
        print(f"Similarity tertinggi: {max_similarity:.4f}")
    else:
        print(f"Tidak dapat memberikan rekomendasi untuk '{anime_title}'")

"""## 9. Evaluasi Model dengan Precision@K

Menghitung Precision@K berdasarkan kesamaan genre
    
    Parameters:
    actual_title (str): Judul anime referensi
    recommended_titles (DataFrame): DataFrame rekomendasi
    k (int): Jumlah rekomendasi yang dievaluasi
    genre_threshold (float): Threshold minimum overlap genre
    
    Returns:
    float: Nilai precision@k
"""

def precision_at_k(actual_title, recommended_titles, k=10, genre_threshold=0.6):
    try:
        # Ambil genre anime referensi
        target_row = anime_df[anime_df['English'] == actual_title]
        if len(target_row) == 0:
            return 0

        target_genres_str = target_row['Genres'].iloc[0]
        if pd.isna(target_genres_str) or target_genres_str == 'Unknown':
            return 0

        target_genres = set([g.strip().lower() for g in target_genres_str.split(',')])

        matches = 0
        evaluated_count = 0

        # Evaluasi setiap rekomendasi
        for title in recommended_titles['English'].head(k):
            rec_row = anime_df[anime_df['English'] == title]
            if len(rec_row) == 0:
                continue

            rec_genres_str = rec_row['Genres'].iloc[0]
            if pd.isna(rec_genres_str) or rec_genres_str == 'Unknown':
                evaluated_count += 1
                continue

            rec_genres = set([g.strip().lower() for g in rec_genres_str.split(',')])

            # Hitung overlap genre
            if len(target_genres) > 0 and len(rec_genres) > 0:
                overlap = len(target_genres.intersection(rec_genres)) / len(target_genres.union(rec_genres))
                if overlap >= genre_threshold:
                    matches += 1

            evaluated_count += 1

        if evaluated_count == 0:
            return 0

        return matches / evaluated_count

    except Exception as e:
        print(f"Error dalam evaluasi {actual_title}: {e}")
        return 0

# Evaluasi sistem rekomendasi
evaluation_results = []

for anime_title, recommendations in recommendation_results.items():
    if recommendations is not None:
        precision = precision_at_k(anime_title, recommendations, k=10, genre_threshold=0.5)
        evaluation_results.append({
            'Anime': anime_title,
            'Precision@10': precision
        })
        print(f"Precision@10 untuk '{anime_title}': {precision:.2f}")

# Hitung rata-rata precision
if evaluation_results:
    avg_precision = np.mean([result['Precision@10'] for result in evaluation_results])
    print(f"\nRata-rata Precision@10: {avg_precision:.2f}")

    # Tampilkan tabel hasil evaluasi
    eval_df = pd.DataFrame(evaluation_results)
    print("\nTabel Hasil Evaluasi:")
    display(eval_df)

"""## 10. Analisis Performa Model"""

# Analisis distribusi similarity scores
all_similarities = []
for anime_title, recommendations in recommendation_results.items():
    if recommendations is not None:
        all_similarities.extend(recommendations['Similarity'].tolist())

if all_similarities:
    plt.figure(figsize=(10, 6))
    sns.histplot(all_similarities, bins=20, kde=True)
    plt.title('Distribusi Similarity Scores dalam Rekomendasi')
    plt.xlabel('Similarity Score')
    plt.ylabel('Frequency')
    plt.show()

    print(f"Statistik Similarity Scores:")
    print(f"- Mean: {np.mean(all_similarities):.4f}")
    print(f"- Median: {np.median(all_similarities):.4f}")
    print(f"- Std: {np.std(all_similarities):.4f}")
    print(f"- Min: {np.min(all_similarities):.4f}")
    print(f"- Max: {np.max(all_similarities):.4f}")

"""## 10. Penyimpanan Model"""

# Simpan model dan data yang diperlukan
model_data = {
    'tfidf_vectorizer': tfidf,
    'cosine_sim_matrix': cosine_sim,
    'anime_data': anime_df,
    'feature_columns': ['English', 'Genres', 'Score', 'Type', 'Episodes', 'Studios', 'Demographic'],
    'content_features_column': 'content_features'
}

joblib.dump(model_data, 'anime_recommender_system.pkl')
print("Model berhasil disimpan sebagai 'anime_recommender_system.pkl'")

"""## 11. Kesimpulan

Sistem rekomendasi anime berbasis konten berhasil dibangun dengan pendekatan **Content-Based Filtering**, menggunakan fitur utama seperti `Genres`, `Type`, `Demographic`, `Source`, dan `Description`. Proses pembangunan sistem melibatkan tahapan analisis data, pembersihan, rekayasa fitur, pemodelan, hingga evaluasi performa.

### Ringkasan Hasil:

1. **Data Understanding**:

   * Dataset terdiri dari 1000 anime dengan 22 fitur.
   * Kolom dengan missing value tertinggi: `Synonyms` (29.1%), `Premiered` (43.1%), `Demographic` (47.9%).
   * Kolom `Genres` memiliki 229 missing value (22.9%) yang telah ditangani.

2. **Data Preparation**:

   * Duplikat dicek dan dipastikan tidak ada.
   * Missing values ditangani menggunakan nilai default yang sesuai konteks.
   * Dilakukan pembersihan karakter khusus dan *stemming* sederhana pada teks.
   * Dibentuk fitur gabungan `content_features` dari berbagai kolom deskriptif.

3. **Modeling**:

   * Ekstraksi fitur teks menggunakan TF-IDF Vectorization (dengan optimasi parameter).
   * Kemiripan konten dihitung menggunakan *Cosine Similarity*.
   * Dihasilkan matriks similarity berukuran 1000x1000.

4. **Evaluation**:

   * Sistem diuji pada lima anime populer dengan metrik **Precision\@10** dan threshold genre overlap ≥ 0.5.
   * Hasil menunjukkan performa rekomendasi yang **bervariasi**, namun secara umum **relevan dengan preferensi konten**.

### Rencana Pengembangan ke Depan:

* Menggabungkan pendekatan **Collaborative Filtering** untuk menangkap pola preferensi pengguna.
* Memberikan **bobot berbeda** pada setiap fitur (misalnya: genre > studio).
* Menggunakan metrik evaluasi tambahan seperti **Recall** dan **F1-Score** untuk pengukuran yang lebih komprehensif.
* Mengintegrasikan **umpan balik eksplisit dari pengguna** untuk meningkatkan personalisasi rekomendasi.
"""